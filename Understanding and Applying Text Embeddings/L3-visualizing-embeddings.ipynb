{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34589b64-1a75-49b1-8e5e-1ea3cd857111",
   "metadata": {},
   "source": [
    "## Lesson 3: Visualizing Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88adc7f3-52b6-432f-80c4-995605b556eb",
   "metadata": {},
   "source": [
    "#### Project environment setup\n",
    "\n",
    "- Load credentials and relevant Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeeebfae-c08f-4c9d-a714-9090a04fbc5c",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "from utils import authenticate\n",
    "credentials, PROJECT_ID = authenticate() #Get credentials and project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b56c0f4-cfc3-4f6a-a189-f30f08cb585e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba3a1c7-2d3a-41de-91b9-d3780801742b",
   "metadata": {},
   "source": [
    "#### Enter project details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3519fb1-7ba3-481b-ac5d-c45cfa6b27a0",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "# Import and initialize the Vertex AI Python SDK\n",
    "\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, \n",
    "              location=REGION, \n",
    "              credentials = credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea550bf-d3fb-4ae2-80da-4f3d9179a9b9",
   "metadata": {},
   "source": [
    "## Embeddings capture meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763e2623-ca37-43ed-90d5-d0e52cc6fba5",
   "metadata": {
    "height": 334
   },
   "outputs": [],
   "source": [
    "in_1 = \"Missing flamingo discovered at swimming pool\"\n",
    "\n",
    "in_2 = \"Sea otter spotted on surfboard by beach\"\n",
    "\n",
    "in_3 = \"Baby panda enjoys boat ride\"\n",
    "\n",
    "\n",
    "in_4 = \"Breakfast themed food truck beloved by all!\"\n",
    "\n",
    "in_5 = \"New curry restaurant aims to please!\"\n",
    "\n",
    "\n",
    "in_6 = \"Python developers are wonderful people\"\n",
    "\n",
    "in_7 = \"TypeScript, C++ or Java? All are great!\" \n",
    "\n",
    "\n",
    "input_text_lst_news = [in_1, in_2, in_3, in_4, in_5, in_6, in_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726ce640-0505-4d01-9620-94502af9eb70",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\n",
    "    \"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270e703-62fd-47cf-893e-3fe7a1282f29",
   "metadata": {},
   "source": [
    "- Get embeddings for all pieces of text.\n",
    "- Store them in a 2D NumPy array (one row for each embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30dbf38d-5f88-4ee0-804c-87099b5d6693",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 5 (char 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 5 (char 4)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_text \u001b[38;5;129;01min\u001b[39;00m input_text_lst_news:\n\u001b[0;32m----> 3\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      5\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(emb)\n\u001b[1;32m      7\u001b[0m embeddings_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(embeddings) \n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/vertexai/language_models/_language_models.py:508\u001b[0m, in \u001b[0;36mTextEmbeddingModel.get_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# instances = [{\"content\": str(text)} for text in texts]\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m#     for prediction in prediction_response.predictions\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     prediction_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dlai_custom_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    510\u001b[0m         TextEmbedding(\n\u001b[1;32m    511\u001b[0m             values\u001b[38;5;241m=\u001b[39mprediction\n\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m prediction_response\n\u001b[1;32m    514\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/vertexai/language_models/_language_models.py:532\u001b[0m, in \u001b[0;36mTextEmbeddingModel._dlai_custom_api\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    527\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_KEY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    530\u001b[0m }\n\u001b[1;32m    531\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39mheaders, data\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(payload))\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 5 (char 4)"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "for input_text in input_text_lst_news:\n",
    "    emb = embedding_model.get_embeddings(\n",
    "        [input_text])[0].values\n",
    "    embeddings.append(emb)\n",
    "    \n",
    "embeddings_array = np.array(embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129943c-d624-4ada-9dbf-8277fc12554d",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "print(\"Shape: \" + str(embeddings_array.shape))\n",
    "print(embeddings_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffaf3d-f57e-4b14-a391-620194c5d354",
   "metadata": {},
   "source": [
    "#### Reduce embeddings from 768 to 2 dimensions for visualization\n",
    "- We'll use principal component analysis (PCA).\n",
    "- You can learn more about PCA in [this video](https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning/lecture/73zWO/reducing-the-number-of-features-optional) from the Machine Learning Specialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa6ec2-fa3b-47da-831a-1892dd8560dc",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA for 2D visualization\n",
    "PCA_model = PCA(n_components = 2)\n",
    "PCA_model.fit(embeddings_array)\n",
    "new_values = PCA_model.transform(embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743daf4-31f3-467d-be38-fc5984857682",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "print(\"Shape: \" + str(new_values.shape))\n",
    "print(new_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328db18-bb41-4405-8139-b62f69850a2a",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "%matplotlib ipympl\n",
    "\n",
    "from utils import plot_2D\n",
    "plot_2D(new_values[:,0], new_values[:,1], input_text_lst_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c789c6-7f12-41ab-96a0-15aea8082a1a",
   "metadata": {},
   "source": [
    "#### Embeddings and Similarity\n",
    "- Plot a heat map to compare the embeddings of sentences that are similar and sentences that are dissimilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dcb75a-abd7-4a45-a78b-3800fb4cf559",
   "metadata": {
    "height": 249
   },
   "outputs": [],
   "source": [
    "in_1 = \"\"\"He couldnâ€™t desert \n",
    "          his post at the power plant.\"\"\"\n",
    "\n",
    "in_2 = \"\"\"The power plant needed \n",
    "          him at the time.\"\"\"\n",
    "\n",
    "in_3 = \"\"\"Cacti are able to \n",
    "          withstand dry environments.\"\"\" \n",
    "\n",
    "in_4 = \"\"\"Desert plants can \n",
    "          survive droughts.\"\"\" \n",
    "\n",
    "input_text_lst_sim = [in_1, in_2, in_3, in_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86c0c3d-87d9-4601-bc03-dd998bf12166",
   "metadata": {
    "height": 130
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_text_lst_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_text \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_text_lst_sim\u001b[49m:\n\u001b[1;32m      3\u001b[0m     emb \u001b[38;5;241m=\u001b[39m embedding_model\u001b[38;5;241m.\u001b[39mget_embeddings([input_text])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(emb)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_text_lst_sim' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "for input_text in input_text_lst_sim:\n",
    "    emb = embedding_model.get_embeddings([input_text])[0].values\n",
    "    embeddings.append(emb)\n",
    "    \n",
    "embeddings_array = np.array(embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5057cff-18dc-42a8-918a-86e54c2e7c0f",
   "metadata": {
    "height": 130
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_text_lst_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_heatmap\n\u001b[0;32m----> 3\u001b[0m y_labels \u001b[38;5;241m=\u001b[39m \u001b[43minput_text_lst_sim\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot the heatmap\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plot_heatmap(embeddings_array, y_labels \u001b[38;5;241m=\u001b[39m y_labels, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings Heatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_text_lst_sim' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import plot_heatmap\n",
    "\n",
    "y_labels = input_text_lst_sim\n",
    "\n",
    "# Plot the heatmap\n",
    "plot_heatmap(embeddings_array, y_labels = y_labels, title = \"Embeddings Heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984ee27-fa85-4839-b799-748b9d82107e",
   "metadata": {},
   "source": [
    "Note: the heat map won't show everything because there are 768 columns to show.  To adjust the heat map with your mouse:\n",
    "- Hover your mouse over the heat map.  Buttons will appear on the left of the heatmap.  Click on the button that has a vertical and horizontal double arrow (they look like axes).\n",
    "- Left click and drag to move the heat map left and right.\n",
    "- Right click and drag up to zoom in.\n",
    "- Right click and drag down to zoom out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075dc41-18e8-40e1-8435-d0f972d0c8ab",
   "metadata": {},
   "source": [
    "#### Compute cosine similarity\n",
    "- The `cosine_similarity` function expects a 2D array, which is why we'll wrap each embedding list inside another list.\n",
    "- You can verify that sentence 1 and 2 have a higher similarity compared to sentence 1 and 4, even though sentence 1 and 4 both have the words \"desert\" and \"plant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff11a0-ae2b-4898-b565-3be7439a27b0",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e99af9-2bf6-4ba5-ad72-809a12c6fca1",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "def compare(embeddings,idx1,idx2):\n",
    "    return cosine_similarity([embeddings[idx1]],[embeddings[idx2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842d87c-1abf-4908-9ff7-ab8b3200532e",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(in_1)\n",
    "print(in_2)\n",
    "print(compare(embeddings,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35860466-0090-4c86-b39a-baf6926b613c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(in_1)\n",
    "print(in_4)\n",
    "print(compare(embeddings,0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f2115e-785b-45a6-acb0-431e015420d5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
